{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Importing the necessary libraries import numpy as np import tensorflow\n",
    "as tf from tensorflow import keras from keras.models import Sequential\n",
    "import pandas as pd from matplotlib import pyplot as plt %matplotlib\n",
    "inline import os import cv2 from keras.layers import Dense, Conv2D,\n",
    "MaxPooling2D, Flatten,GlobalAveragePooling2D from PIL import Image from\n",
    "sklearn.preprocessing import LabelEncoder from sklearn.metrics import\n",
    "confusion_matrix, classification_report\n",
    "\n",
    "# Defining the paths to your image and csv folders\n",
    "\n",
    "train_val_dir = “/content/C:\\_valdrive/MyDrive/charts/train_val”\n",
    "test_dir = “/content/C:/MyDrive/charts/test” train_path_labels =\n",
    "“/content/C:\\_val.csv” train_val_labels = pd.read_csv(train_path_labels)\n",
    "\n",
    "# loading the training dataset in numpy array\n",
    "\n",
    "images = \\[\\] labels = \\[\\] for filename in os.listdir(train_val_dir):\n",
    "if filename.endswith(‘.png’): \\# Loading the images and resize them to\n",
    "(128, 128) with 3 color channels img =\n",
    "cv2.imread(os.path.join(train_val_dir, filename)) img = cv2.resize(img,\n",
    "(128, 128)) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # img = Image.open(os.path.join(train_val_dir, filename))\n",
    "    img_array = np.array(img)\n",
    "    # Appending the array to the list of images\n",
    "    images.append(img_array)\n",
    "    labels.append(filename)\n",
    "\n",
    "# Converting the string labels to numerical labels\n",
    "\n",
    "le = LabelEncoder() labels = le.fit_transform(labels)\n",
    "\n",
    "# Converting the lists to NumPy arrays\n",
    "\n",
    "images = np.array(images) labels = np.array(labels) \\# Save the arrays\n",
    "in NumPy format np.save(‘x_train.npy’, images) np.save(‘y_train.npy’,\n",
    "labels) x_train = np.load(‘x_train.npy’) y_train =\n",
    "np.load(‘y_train.npy’)\n",
    "\n",
    "x_train.shape x_train\\[:5\\]\n",
    "\n",
    "# loading test dataset in numpy array\n",
    "\n",
    "images = \\[\\] labels = \\[\\] for filename in os.listdir(test_dir): if\n",
    "filename.endswith(‘.png’): img = cv2.imread(os.path.join(test_dir,\n",
    "filename)) img = cv2.resize(img, (128, 128)) img = cv2.cvtColor(img,\n",
    "cv2.COLOR_BGR2RGB) img_array = np.array(img) images.append(img_array)\n",
    "labels.append(filename)\n",
    "\n",
    "# Converting the string labels to numerical labels\n",
    "\n",
    "le = LabelEncoder() labels = le.fit_transform(labels) images =\n",
    "np.array(images) labels = np.array(labels)\n",
    "\n",
    "# Saving the arrays in NumPy format\n",
    "\n",
    "np.save(‘x_test.npy’, images) np.save(‘y_test.npy’, labels) x_test =\n",
    "np.load(‘x_test.npy’) y_test = np.load(‘y_test.npy’)\n",
    "\n",
    "# Converting the lists to NumPy array\n",
    "\n",
    "image_classes = \\[‘line’, ‘dot_line’, ‘hbar_categorical’,\n",
    "‘vbar_categorical’, ‘pie’\\] image_classes\\[0\\] \\# map the categories to\n",
    "the labels array i.e y_train label_map = {‘line’: 0, ‘dot_line’: 1,\n",
    "‘hbar_categorical’: 2, ‘vbar_categorical’: 3, ‘pie’: 4} y_train =\n",
    "np.array(\\[label_map\\[label\\] for label in train_val_labels\\[‘type’\\]\\])\n",
    "\n",
    "y_train x_train=x_train /255 x_test=x_train /255 y_train_index =\n",
    "train_val_labels\\[‘image_index’\\] y_train_type =\n",
    "train_val_labels\\[‘type’\\] y_train_type\\[:5\\]\n",
    "\n",
    "# Splitting the training images and labels into training and validation sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split x_train, x_test,\n",
    "y_train, y_test = train_test_split(x_train, y_train, test_size=0.2,\n",
    "random_state=42) cnn_model = Sequential(\\[ Conv2D(filters=16\n",
    ",kernel_size=(3,3), activation=‘relu’, input_shape=(128,128,3)),\n",
    "MaxPooling2D(pool_size=(2,2)), Conv2D(32, (3,3), activation=‘relu’),\n",
    "MaxPooling2D(pool_size=(2,2)), Conv2D(64, (3,3), activation=‘relu’),\n",
    "MaxPooling2D(pool_size=(2,2)), Flatten(), Dense(128, activation=‘relu’),\n",
    "Dense(5, activation=‘softmax’)\\])\n",
    "\n",
    "# Compiling the model\n",
    "\n",
    "cnn_model.compile(optimizer=‘adam’,\n",
    "loss=‘sparse_categorical_crossentropy’, metrics=\\[‘accuracy’\\])\n",
    "\n",
    "# Training the model\n",
    "\n",
    "history = cnn_model.fit(x_train, y_train, batch_size=1000,\n",
    "epochs=50,validation_data=(x_test, y_test)) \\# Plot the obtained loss\n",
    "plt.plot(history.history\\[‘loss’\\])\n",
    "plt.plot(history.history\\[‘val_loss’\\]) plt.title(‘Model Loss’)\n",
    "plt.ylabel(‘Loss’) plt.xlabel(‘Epoch’) plt.legend(\\[‘Train’,\n",
    "‘Validation’\\], loc=‘upper right’) plt.show()\n",
    "cnn_model.evaluate(x_test,y_test) def image_sample(x, y, index):\n",
    "plt.figure(figsize = (10,2)) plt.imshow(x\\[index\\])\n",
    "\n",
    "# image_label = train_val_labels.iloc\\[index\\]\\[‘type’\\]\n",
    "\n",
    "# plt.xlabel(image_label)\n",
    "\n",
    "plt.xlabel(image_classes\\[y\\[index\\]\\]) image_sample(x_test,y_test,1)\n",
    "image_sample(x_test,y_test,50) image_sample(x_test,y_test,25) y_pred =\n",
    "cnn_model.predict(x_test) y_pred\\[:5\\] y_classes = \\[np.argmax(element)\n",
    "for element in y_pred\\] y_classes\\[:5\\]\n",
    "\n",
    "y_test\\[:5\\]\n",
    "\n",
    "# test actual and predicted\n",
    "\n",
    "# image_sample(x_test,y_test,1) #actual\n",
    "\n",
    "# image_classes\\[y_classes\\[1\\]\\] #predicted\n",
    "\n",
    "# image_sample(x_test,y_test,10) #actual\n",
    "\n",
    "# image_classes\\[y_classes\\[10\\]\\] #predicted\n",
    "\n",
    "image_sample(x_test,y_test,15) #actual image_classes\\[y_classes\\[15\\]\\]\n",
    "#predicted\n",
    "\n",
    "print(“classification report: ”,\n",
    "classification_report(y_test,y_classes))\n",
    "\n",
    "# Generating the confusion matrix\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_classes) print(‘Confusion\n",
    "Matrix:’) print(conf_mat)\n",
    "\n",
    "#Plotting the confusion matrix import seaborn as sn plt.figure(figsize =\n",
    "(10,10)) sn.heatmap(conf_mat,annot=True,fmt=‘d’) plt.xlabel(‘Predicted’)\n",
    "plt.ylabel(‘Actual’) from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Loading the pre-trained model\n",
    "\n",
    "vgg16_model = VGG16(weights=‘imagenet’, include_top=False,\n",
    "input_shape=(224, 224, 3))\n",
    "\n",
    "# Replacing the final classification layer with a new layer\n",
    "\n",
    "x = vgg16_model.output x = GlobalAveragePooling2D()(x) x = Dense(128,\n",
    "activation=‘relu’)(x) predictions = Dense(5, activation=‘softmax’)(x)\n",
    "pt_model = tf.keras.Model(inputs=vgg16_model.input, outputs=predictions)\n",
    "for layer in pt_model.layers: layer.trainable = False\n",
    "\n",
    "# Printing the summary of the model architecture\n",
    "\n",
    "pt_model.summary() train_datagen = ImageDataGenerator( rescale=1./255,\n",
    "rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "fill_mode=‘nearest’) test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# flow method generates batches of augmented data\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
    "test_generator = train_datagen.flow(x_test, y_test, batch_size=32)\n",
    "plt.plot(history.history\\[‘loss’\\])\n",
    "plt.plot(history.history\\[‘val_loss’\\]) plt.title(‘Model Loss’)\n",
    "plt.ylabel(‘Loss’) plt.xlabel(‘Epoch’) plt.legend(\\[‘Train’,\n",
    "‘Validation’\\], loc=‘upper right’) plt.show()"
   ],
   "id": "40126dcf-40fa-4320-a1eb-190438906d36"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
